{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed6bb15",
   "metadata": {},
   "source": [
    "# Your First Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6707052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13580.000000</td>\n",
       "      <td>1.358000e+04</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13518.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>7130.000000</td>\n",
       "      <td>8205.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.075684e+06</td>\n",
       "      <td>10.137776</td>\n",
       "      <td>3105.301915</td>\n",
       "      <td>2.914728</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>1.610075</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>151.967650</td>\n",
       "      <td>1964.684217</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "      <td>7454.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.955748</td>\n",
       "      <td>6.393107e+05</td>\n",
       "      <td>5.868725</td>\n",
       "      <td>90.676964</td>\n",
       "      <td>0.965921</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>541.014538</td>\n",
       "      <td>37.273762</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>4378.581772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000e+05</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "      <td>4380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.030000e+05</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "      <td>6555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>44515.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms         Price      Distance      Postcode      Bedroom2  \\\n",
       "count  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \n",
       "mean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \n",
       "std        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \n",
       "min        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n",
       "25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n",
       "50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n",
       "75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \n",
       "max       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n",
       "\n",
       "           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\n",
       "count  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \n",
       "mean       1.534242      1.610075     558.416127    151.967650  1964.684217   \n",
       "std        0.691712      0.962634    3990.669241    541.014538    37.273762   \n",
       "min        0.000000      0.000000       0.000000      0.000000  1196.000000   \n",
       "25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n",
       "50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n",
       "75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \n",
       "max        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n",
       "\n",
       "          Lattitude    Longtitude  Propertycount  \n",
       "count  13580.000000  13580.000000   13580.000000  \n",
       "mean     -37.809203    144.995216    7454.417378  \n",
       "std        0.079260      0.103916    4378.581772  \n",
       "min      -38.182550    144.431810     249.000000  \n",
       "25%      -37.856822    144.929600    4380.000000  \n",
       "50%      -37.802355    145.000100    6555.000000  \n",
       "75%      -37.756400    145.058305   10331.000000  \n",
       "max      -37.408530    145.526350   21650.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = \"./melb_data.csv\"\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "melbourne_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5b3e0",
   "metadata": {},
   "source": [
    "## Selecting Data For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed69e1",
   "metadata": {},
   "source": [
    "You can pull out a variable using **dot-notation**. This single column is stores in a *Series*, which is a DataFrame with a single column of data\n",
    "\n",
    "We will use *dot notation* to select a column that we want to predict. This is called the *prediction target*. By convention, we will call it y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d610337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melbourne_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3cb79",
   "metadata": {},
   "source": [
    "## Drop missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a2d7d",
   "metadata": {},
   "source": [
    "The data has missing values (some houses have no variables recorded). We will use \"dropna\", which drops missnig values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4339e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_data = melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369cee5",
   "metadata": {},
   "source": [
    "## Selecting the Prediction Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d5cae",
   "metadata": {},
   "source": [
    "To select a single column of data from a DataFrame, we can use **dot notation** and save it as a Series object. In this case, we are selecting the column that we want to use as the prediction target, which is conventionally referred to as **\"y\"**. Therefore, to save the house prices from the Melbourne dataset, we can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92406a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = melbourne_data.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895dcf9a",
   "metadata": {},
   "source": [
    "## Choosing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d5884",
   "metadata": {},
   "source": [
    "The inputs to our model, which are used to make predictions, are referred to as \"features.\" In our case, the features are the columns used to determine the home price. Depending on the situation, we may use all columns except the target as features or we may choose to use only a subset of features.\n",
    "\n",
    "For the current model, we will use only a few features.\n",
    "\n",
    "One cam select multiple features like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b59dcc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_features = [\"Rooms\", \"Bathroom\", \"Landsize\", \"Lattitude\", \"Longtitude\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccf7aa",
   "metadata": {},
   "source": [
    "Again, conventionally this is called **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d92c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = melbourne_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a2b4f",
   "metadata": {},
   "source": [
    "The code **melbourne_data[melbourne_features]** is used to create a new DataFrame **X** containing only the columns of the original DataFrame **melbourne_data** that are listed in the melbourne_features list.\n",
    "\n",
    "This line of code uses square bracket notation to subset the melbourne_data DataFrame and select only the columns that are present in the melbourne_features list. This new DataFrame X will be used as the input (i.e., feature matrix) for the machine learning model that we will build to predict home prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "529781ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms     Bathroom      Landsize    Lattitude   Longtitude\n",
       "count  6196.000000  6196.000000   6196.000000  6196.000000  6196.000000\n",
       "mean      2.931407     1.576340    471.006940   -37.807904   144.990201\n",
       "std       0.971079     0.711362    897.449881     0.075850     0.099165\n",
       "min       1.000000     1.000000      0.000000   -38.164920   144.542370\n",
       "25%       2.000000     1.000000    152.000000   -37.855438   144.926198\n",
       "50%       3.000000     1.000000    373.000000   -37.802250   144.995800\n",
       "75%       4.000000     2.000000    628.000000   -37.758200   145.052700\n",
       "max       8.000000     8.000000  37000.000000   -37.457090   145.526350"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca33554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-37.8024</td>\n",
       "      <td>144.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-37.8060</td>\n",
       "      <td>144.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
       "1      2       1.0     156.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0   -37.8093    144.9944\n",
       "4      4       1.0     120.0   -37.8072    144.9941\n",
       "6      3       2.0     245.0   -37.8024    144.9993\n",
       "7      2       1.0     256.0   -37.8060    144.9954"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a3632",
   "metadata": {},
   "source": [
    "## Building Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa44510",
   "metadata": {},
   "source": [
    "To create machine learning models, we will be using the scikit-learn library, commonly abbreviated as sklearn. Scikit-learn is a widely-used library for building models on tabular (i.e., spreadsheet-like) data such as DataFrames.\n",
    "\n",
    "There are four main steps involved in building and using a machine learning model:\n",
    "\n",
    "1. **Define**: We need to determine what type of model we want to use and set any relevant parameters. For example, we might choose to use a decision tree model, and we would need to specify the maximum depth of the tree.\n",
    "2. **Fit**: This is the process of training the model on a given set of input data, allowing it to learn the patterns in the data.\n",
    "3. **Predict**: After the model has been trained, we can use it to make predictions on new data.\n",
    "4. **Evaluate**: Finally, we need to determine how accurate the model's predictions are by comparing them to the true values (i.e., the targets) for a set of data that was not used in training. There are several metrics that can be used to evaluate model performance, such as mean squared error or R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72a1d5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "melbourne_model = DecisionTreeRegressor(random_state= 1)\n",
    "\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68510870",
   "metadata": {},
   "source": [
    "The first line of code from **sklearn.tree import DecisionTreeRegressor** imports the DecisionTreeRegressor class from the scikit-learn tree module. This class will be used to define and train a decision tree regression model.\n",
    "\n",
    "The second line of code **melbourne_model = DecisionTreeRegressor(random_state= 1)** creates an instance of the DecisionTreeRegressor class and assigns it to the variable melbourne_model. The **random_state** parameter is set to 1 to ensure that the results are reproducible.\n",
    "\n",
    "The third line of code **melbourne_model.fit(X, y)** trains the decision tree regression model on the input features X and target variable y. During the fitting process, the model learns to capture the patterns in the training data and to make predictions of the target variable based on the input features. Once the model is trained, we can use it to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785b93c",
   "metadata": {},
   "source": [
    "In practice, you'll want to make predictions for new houses coming on the market rather than the houses we already have prices for. But we'll make predictions for the first few rows of the training data to see how the predict function works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5c98c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for 5 houses: \n",
      "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "1      2       1.0     156.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0   -37.8093    144.9944\n",
      "4      4       1.0     120.0   -37.8072    144.9941\n",
      "6      3       2.0     245.0   -37.8024    144.9993\n",
      "7      2       1.0     256.0   -37.8060    144.9954\n",
      "Predictions are: \n",
      "[1035000. 1465000. 1600000. 1876000. 1636000.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Making predictions for 5 houses: \")\n",
    "print(X.head())\n",
    "print(\"Predictions are: \")\n",
    "print(melbourne_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d565730f",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01207302",
   "metadata": {},
   "source": [
    "When evaluating a model, it is important to measure its predictive accuracy. However, a common mistake is to make predictions using the training data and compare them to the target values in the same data. This approach can be problematic, and we need to find a better way.\n",
    "\n",
    "To summarize the model's quality in a meaningful way, we need to use a metric. One such metric is Mean Absolute Error (MAE), which can help us summarize the accuracy of the model's predictions in a single number. This is much more useful than looking at a list of predicted and actual values for each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7466e6",
   "metadata": {},
   "source": [
    "To evaluate the accuracy of a model's predictions, we can use a metric called Mean Absolute Error (MAE). This metric involves taking the absolute value of each prediction error (i.e., the difference between the predicted value and the actual value) and averaging those absolute errors.\n",
    "\n",
    "For example, if the actual value of a house is 150,000 dollars and the model predicts it to be 100,000 dollars, the prediction error would be 50,000 dollars. By taking the absolute value of this error, we get a positive number of 50,000 dollars. We would do this for each prediction and actual value pair, then calculate the average of all the absolute errors to get the MAE.\n",
    "\n",
    "The resulting MAE value tells us, on average, how much our model's predictions are off. A smaller MAE value indicates better predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218b7e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = './melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad28996",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We have the model, now lets calculate the mean absolute error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2666911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434.71594577146544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87de248",
   "metadata": {},
   "source": [
    "\n",
    "When evaluating a model's performance, it is important to consider its ability to make accurate predictions on **new data**, rather than just the data used to build the model. The evaluation metric calculated on the same data used to build the model is known as an **\"in-sample\"** score.\n",
    "\n",
    "However, relying solely on in-sample scores can be misleading. For example, a model may identify a pattern in the training data that does not hold true in the larger population. This can result in **inaccurate predictions** when the model is used on new data.\n",
    "\n",
    "To avoid this problem, it is common practice to set aside some data from the training set to use as a validation set. The model is built on the remaining data, and its performance is evaluated on the validation set. This provides a more realistic estimate of the model's performance on new, unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596f46c",
   "metadata": {},
   "source": [
    "*Data sourced from Kaggle*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df134f51",
   "metadata": {},
   "source": [
    "# Underfitting and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109a2b3",
   "metadata": {},
   "source": [
    "In practical applications, it's common for a decision tree to have 10 splits between the top level (all houses) and a leaf. As the tree gets **deeper**, the dataset gets divided into smaller groups of houses, resulting in fewer houses in each leaf. If there are only a few houses in a leaf, the predictions may be accurate for those houses, but not for new data, which can cause **overfitting**. However, if the tree is **too shallow**, the houses won't be divided into distinct enough groups, causing **underfitting**. If a tree divides houses into only 2 or 4 groups, the predictions may be inaccurate even for the training data. Therefore, finding the right balance in dividing the houses into groups is crucial for **accurate predictions**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125826a",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e06cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, trani_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf03a8",
   "metadata": {},
   "source": [
    "The function takes five arguments:\n",
    "\n",
    "1) **\"max_leaf_nodes\"**: an integer specifying the maximum number of leaf nodes for the decision tree model.\n",
    "2) **\"train_X\"**: a Pandas DataFrame containing the features of the training set.\n",
    "3) **\"val_X\"**: a Pandas DataFrame containing the features of the validation set.\n",
    "4) **\"train_y\"**: a Pandas Series containing the target values of the training set.\n",
    "5) **\"val_y\"**: a Pandas Series containing the target values of the validation set.\n",
    "\n",
    "Within the function, a decision tree regression model is initialized with the specified maximum number of leaf nodes and a fixed random seed of 0 using the DecisionTreeRegressor class from scikit-learn. The model is then trained on the training set using the fit() method of the model object. The predict() method is used to generate predictions on the validation set, and the mean absolute error between the actual target values and the predicted target values is computed using the mean_absolute_error() function from scikit-learn.\n",
    "\n",
    "Finally, the computed MAE is returned by the function as a float value. The purpose of this function is to allow for the comparison of the performance of different decision tree models with varying maximum number of leaf nodes on a validation set, which can be useful in tuning the hyperparameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3b90060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "melbourne_file_path = 'melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8187fb",
   "metadata": {},
   "source": [
    "First, the Pandas library is imported as \"pd\". The file path to the Melbourne dataset is stored in a variable called \"melbourne_file_path\". Then, the dataset is loaded into a Pandas DataFrame called \"melbourne_data\" using the read_csv() function.\n",
    "\n",
    "The next line drops any rows with **missing values** from the dataset using the dropna() method with the argument \"axis=0\". This creates a new DataFrame called \"filtered_melbourne_data\" that contains only the rows with **complete data**.\n",
    "\n",
    "The **target variable**, which is the **price of the houses** in the dataset, is assigned to a Pandas Series called **\"y\"**. The **list** of features that will be used as **predictor variables** in the machine learning model is assigned to a list called \"melbourne_features\". Then, the predictor variables are extracted from the filtered dataset using the indexing operator, and are **stored in** a new DataFrame called **\"X\"**.\n",
    "\n",
    "The next step is to split the data into **training** and **validation** sets using the train_test_split() function from scikit-learn. The function takes the **predictor variables (X)** and the **target variable (y)** as arguments, along with the \"random_state\" parameter set to 0 for reproducibility of the split. The function returns four sets of data: the **training set of predictor variables** and **target variable (train_X and train_y)**, and the **validation set of predictor variables** and **target variable (val_X and val_y)**.\n",
    "\n",
    "This technique of splitting the data into training and validation sets is a common practice in machine learning to evaluate the performance of the model on data it has not seen before. The training set is used to fit the model to the data, while the validation set is used to evaluate how well the model generalizes to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cf3f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  347380\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  258171\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  243495\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  254983\n"
     ]
    }
   ],
   "source": [
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f3f30b",
   "metadata": {},
   "source": [
    "Of the options listed, **500** is the optimal number of leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1084e5a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deecfa4b",
   "metadata": {},
   "source": [
    "1. **Overfitting** occurs when a model captures noise or patterns that exist only in the training data, leading to poor performance in making predictions on new data.\n",
    "2. **Underfitting** occurs when a model is too simple to capture the underlying patterns in the data, also leading to poor performance. \n",
    "\n",
    "To prevent this, we use validation data that the model hasn't seen during training to evaluate the model's performance. This allows us to try out various models and select the best one that performs well on both the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254e739",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96bae1",
   "metadata": {},
   "source": [
    "\n",
    "When building a decision tree, there is a trade-off between **overfitting** and **underfitting**. A **deep tree** with many leaves may overfit the training data, as it relies on information from only a few houses at each leaf. On the other hand, a **shallow tree** with few leaves may underfit the data and miss important distinctions.\n",
    "\n",
    "Even the most advanced modeling techniques still struggle with this trade-off. However, some models have found ways to achieve better performance. One such model is the **random forest**, which uses **multiple trees** and **averages their predictions** to make a final prediction. This approach often results in much better predictive accuracy than a single decision tree. Additionally, random forests tend to perform well with their **default parameters**. More advanced models can be trained for even better performance, but this often requires careful parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26e9ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "melbourne_file_path = './melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "y = melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3d4bd",
   "metadata": {},
   "source": [
    "We build a **random forest model** similarly to how we built a **decision tree** in scikit-learn - this time using the **RandomForestRegressor** class instead of DecisionTreeRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8092ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191669.7536453626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state = 1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46015786",
   "metadata": {},
   "source": [
    "This code imports the **RandomForestRegressor model** from the scikit-learn library, which is a type of **ensemble model** that trains **multiple decision trees** and **combines their predictions** to make a final prediction. It also imports the mean_absolute_error function from the same library, which is used to **measure the performance of the model**.\n",
    "\n",
    "The code then creates an **instance** of the RandomForestRegressor model with a specified **random state** and **assigns** it to the variable **forest_model**. It fits the model to the **training data** using the **fit method**, which trains the model on the training set.\n",
    "\n",
    "Next, the model makes **predictions** on the **validation set** using the **predict method**, and the mean_absolute_error function is used to **calculate the mean absolute error between the predicted values and the actual values in the validation set**. The mean absolute error is a common evaluation metric that measures the average absolute difference between the predicted values and the actual values. Finally, the mean absolute error is printed to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c72c82",
   "metadata": {},
   "source": [
    "*Data sourced from Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f7195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
